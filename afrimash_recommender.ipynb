{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbPvOhMuIIXGzAaVLRU7j+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kojomensahonums/AI4Startups-datathon/blob/master/afrimash_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import random"
      ],
      "metadata": {
        "id": "lR6chQDOEgZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 1. LOAD DATA\n",
        "# ============================================\n",
        "transactions = pd.read_excel(\"/content/trans_subset_exploded.xlsx\")\n",
        "rfm = pd.read_excel(\"/content/RFM_Data.xlsx\")\n",
        "\n",
        "# Clean product text\n",
        "transactions[\"Product(s)\"] = transactions[\"Product(s)\"].str.replace(r\"\\d+×\", \"\", regex=True).str.strip()\n",
        "transactions[\"Product(s)\"] = transactions[\"Product(s)\"].str.replace(r\"\\s+\", \" \", regex=True)\n",
        "transactions = transactions[transactions[\"Product(s)\"].astype(str).str.strip().ne(\"\")].dropna(subset=[\"Product(s)\"])"
      ],
      "metadata": {
        "id": "PskOBNeNEjlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 2. BUILD PRODUCT CONTENT SIMILARITY\n",
        "# ============================================\n",
        "# Clean product text\n",
        "transactions[\"Product(s)\"] = transactions[\"Product(s)\"].astype(str)\n",
        "transactions[\"Product(s)\"] = transactions[\"Product(s)\"].str.replace(r\"\\d+×\", \"\", regex=True).str.strip()\n",
        "transactions[\"Product(s)\"] = transactions[\"Product(s)\"].str.replace(r\"\\s+\", \" \", regex=True)\n",
        "\n",
        "# Drop rows with empty or missing product names\n",
        "transactions = transactions[transactions[\"Product(s)\"].notna()]\n",
        "transactions = transactions[transactions[\"Product(s)\"].str.strip() != \"\"]\n",
        "\n",
        "# Model\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(transactions[\"Product(s)\"])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Product lookup\n",
        "product_indices = pd.Series(transactions.index, index=transactions[\"Product(s)\"]).drop_duplicates()\n",
        "\n",
        "def get_content_recommendations(product_name, top_n=10):\n",
        "    # Skip invalid product names\n",
        "    if pd.isna(product_name) or product_name.strip() == \"\":\n",
        "        return []\n",
        "\n",
        "    # If product not in index, skip\n",
        "    if product_name not in product_indices:\n",
        "        return []\n",
        "\n",
        "    # Get the index (handle duplicates safely)\n",
        "    idx = product_indices[product_name]\n",
        "    if isinstance(idx, (pd.Series, list, np.ndarray)):\n",
        "        idx = idx.iloc[0] if isinstance(idx, pd.Series) else idx[0]\n",
        "\n",
        "    # Compute similarity\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:top_n+1]  # skip the item itself\n",
        "\n",
        "    # Get product names of top similar items\n",
        "    product_indices_top = [i[0] for i in sim_scores]\n",
        "    return transactions.iloc[product_indices_top][\"Product(s)\"].tolist()\n",
        "\n"
      ],
      "metadata": {
        "id": "XkeuPSdsEsN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 3. BUILD COLLABORATIVE FILTERING\n",
        "# ============================================\n",
        "# Create product basket per order\n",
        "basket = transactions.groupby(['Order #'])['Product(s)'].apply(list).reset_index()\n",
        "\n",
        "# Build co-occurrence matrix\n",
        "from collections import defaultdict\n",
        "co_matrix = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "for row in basket['Product(s)']:\n",
        "    for i in range(len(row)):\n",
        "        for j in range(i+1, len(row)):\n",
        "            co_matrix[row[i]][row[j]] += 1\n",
        "            co_matrix[row[j]][row[i]] += 1\n",
        "\n",
        "def get_collab_recommendations(product_name, top_n=10):\n",
        "    related = co_matrix.get(product_name, {})\n",
        "    sorted_related = sorted(related.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [k for k, _ in sorted_related[:top_n]]\n"
      ],
      "metadata": {
        "id": "Omp6_T1pE0lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9iYqlH4EJr6"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 4. HYBRID RECOMMENDER\n",
        "# ============================================\n",
        "# ============================================\n",
        "# 4. HYBRID RECOMMENDER (Optimized & Personalized)\n",
        "# ============================================\n",
        "def hybrid_recommend(customer_id, top_n=10):\n",
        "    \"\"\"\n",
        "    Returns top N recommended products for a given customer.\n",
        "    Hybrid approach combining content + collaborative + recency weighting.\n",
        "    \"\"\"\n",
        "\n",
        "    # === 1. Handle case where customer doesn't exist in transactions ===\n",
        "    if customer_id not in transactions[\"Customer_ID\"].unique():\n",
        "        popular_products = transactions[\"Product(s)\"].dropna().value_counts().index.tolist()\n",
        "        if len(popular_products) >= top_n:\n",
        "            return random.sample(popular_products[:30], k=min(top_n, 10))\n",
        "        return popular_products[:top_n]\n",
        "\n",
        "    # === 2. Get customer type and recent purchase history ===\n",
        "    cust_type = rfm.loc[rfm[\"Customer_ID\"] == customer_id, \"Customer_Type\"].values\n",
        "    cust_type = cust_type[0] if len(cust_type) > 0 else \"new\"\n",
        "\n",
        "    cust_orders = transactions[transactions[\"Customer_ID\"] == customer_id].copy()\n",
        "    cust_orders = cust_orders.sort_values(\"datetime\", ascending=False)\n",
        "    purchased = cust_orders[\"Product(s)\"].dropna().unique()\n",
        "\n",
        "    # === 3. Compute recency weights (recent products = higher influence) ===\n",
        "    recency_weights = {\n",
        "        prod: 1.0 - (i / max(len(cust_orders), 1)) * 0.5\n",
        "        for i, prod in enumerate(cust_orders[\"Product(s)\"])\n",
        "    }\n",
        "\n",
        "    recommendations = {}\n",
        "\n",
        "    # === 4. Generate product-level recommendations ===\n",
        "    for prod in purchased:\n",
        "        if not isinstance(prod, str) or prod.strip().lower() == 'nan':\n",
        "            continue\n",
        "\n",
        "        # Content-based + collaborative\n",
        "        content_recs = get_content_recommendations(prod, top_n)\n",
        "        collab_recs = get_collab_recommendations(prod, top_n)\n",
        "\n",
        "        # Clean invalids\n",
        "        content_recs = [r for r in content_recs if isinstance(r, str) and r.strip().lower() != 'nan']\n",
        "        collab_recs = [r for r in collab_recs if isinstance(r, str) and r.strip().lower() != 'nan']\n",
        "\n",
        "        # Weight by customer type\n",
        "        if cust_type == \"new\":\n",
        "            combined = content_recs[:6] + collab_recs[:4]\n",
        "        else:\n",
        "            combined = collab_recs[:6] + content_recs[:4]\n",
        "\n",
        "        # Add recency-based weight\n",
        "        weight = recency_weights.get(prod, 1.0)\n",
        "        for r in combined:\n",
        "            if r not in purchased:\n",
        "                recommendations[r] = recommendations.get(r, 0) + weight\n",
        "\n",
        "    # === 5. Sort recommendations by score ===\n",
        "    ranked = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_items = [r[0] for r in ranked[:top_n]]\n",
        "\n",
        "    # === 6. Diversity control: avoid duplicates of same product family ===\n",
        "    diversified = []\n",
        "    for item in top_items:\n",
        "        # Skip duplicates of the same leading keyword\n",
        "        if not any(item.split()[0].lower() in x.lower() for x in diversified):\n",
        "            diversified.append(item)\n",
        "    top_items = diversified[:top_n]\n",
        "\n",
        "    # === 7. Fallback if not enough unique recommendations ===\n",
        "    if len(top_items) < top_n:\n",
        "        popular_products = transactions[\"Product(s)\"].dropna().value_counts().index.tolist()\n",
        "        for prod in popular_products:\n",
        "            if prod not in purchased and prod not in top_items:\n",
        "                top_items.append(prod)\n",
        "            if len(top_items) >= top_n:\n",
        "                break\n",
        "\n",
        "    # === 8. Final cleanup ===\n",
        "    top_items = [r for r in top_items if isinstance(r, str) and r.strip().lower() != 'nan']\n",
        "\n",
        "    return top_items[:top_n]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hybrid_recommend('CUS4200075', top_n=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9luccJZICbl",
        "outputId": "d3c0c4ed-f1ab-4910-d85a-cacebecb8aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pigs',\n",
              " 'Commercial Day Old Arbor Acres Plus Broilers Chicks (Grinphield Brand)',\n",
              " 'Poultry Management For First-Timers (E-Book)',\n",
              " 'Commercial SAYED Broilers (Day-Old Chicks)',\n",
              " 'Day-Old Marshall Broilers (Grinphield)',\n",
              " 'AMO Broilers (Commercial Arbor Acres Plus)',\n",
              " 'Commercial Day-Old Arbor Acres Plus (FIDAN Broilers)',\n",
              " 'Agrited Broilers',\n",
              " 'Commercial Day-Old ZARTECH Broilers (Cobb 500)',\n",
              " 'Agrited Broiler | Commercial Day Old Broilers Ross 308']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 6. (OPTIONAL) LINK IMAGES\n",
        "# ============================================\n",
        "# To activate later, uncomment this section and supply image links\n",
        "# product_images = pd.read_excel(\"product_images.xlsx\")  # columns: Product, Image_URL\n",
        "# recommendations_df = recommendations_df.explode(\"Recommended_Products\")\n",
        "# recommendations_df = recommendations_df.merge(product_images,\n",
        "#                                               left_on=\"Recommended_Products\",\n",
        "#                                               right_on=\"Product\",\n",
        "#                                               how=\"left\")\n",
        "\n",
        "# ============================================\n",
        "# 7. SAVE OUTPUT\n",
        "# ============================================\n",
        "recommendations_df.to_csv(\"recommendations.csv\", index=False)\n",
        "print(\"✅ Recommendations generated and saved to recommendations.csv\")\n"
      ],
      "metadata": {
        "id": "VhR2ABpRE79t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}